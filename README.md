# Intel-Project

Problem Statement : Running GenAI on Intel AI Laptops and Simple LLM Inference on CPU and fine-tuning of LLM Models using Intel® OpenVINO™

Introduction To The Project :
This project focuses on leveraging Intel AI laptops for running generative AI (GenAI) applications and performing simple large language model (LLM) inference on CPUs. It includes fine-tuning LLM models using Intel® OpenVINO™, a toolkit designed to optimize and accelerate AI workloads. By utilizing Intel's hardware and software solutions, the project aims to achieve efficient and high-performance AI model deployment and customization, making advanced AI capabilities accessible and practical for various applications on consumer-grade hardware.

It involves developing an AI application that offers two key features: text generation and a Q&A-based chatbot. The text generation feature is designed to create coherent and contextually relevant text based on user input, making it useful for tasks such as content creation and automated writing. The Q&A-based chatbot, on the other hand, is tailored to handle simple queries, providing users with quick and accurate responses. Together, these features aim to enhance user interaction, offering both creative and informational support, and are particularly beneficial for applications requiring dynamic content and efficient information retrieval.

Presentation : https://drive.google.com/file/d/1mfh0Y_3yOF_4rihMTsgDgc1OOu8ag2S2/view?usp=sharing
